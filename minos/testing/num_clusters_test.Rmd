---
params:
    out_path: '' # default arguments. specify others in command line.
    intervention: ''
    baseline: ''
title: "`r paste(params$file_path, ' ', params$intervention, ' NUM CLUSTER CHECK')`"
output: 
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: true
    df_print: paged
    code_folding: hide
---

# SETUP

```{r "setup", include=FALSE}

require(tidyverse)
require(ggplot2)
require(knitr)
require(here)
require(cluster)
require(clustMixType)

#workingDir <- "/home/luke/Documents/WORK/MINOS/"
workingDir <- normalizePath('../')
knitr::opts_knit$set(root.dir = workingDir)
knitr::opts_chunk$set(
)
rm(workingDir)
```

Source utils for some functions.

```{r}
source(here::here('minos', 'transitions', 'utils.R'))
source(here::here('minos', 'utils_datain.R'))
source(here::here('minos', 'utils_validation_vis.R'))
source(here::here('minos', 'validation', 'utils.r'))
source(here::here('minos', 'utils_S7.R'))
```

## Data

```{r}
out.path.batch <- here::here('output', params$out_path)
intervention <- params$intervention
baseline <- params$baseline
if (baseline == '') {
  baseline <- 'baseline'
}

base.dat <- read.csv(file = paste0(out.path.batch, baseline, '_summary.csv'))
int.dat <- read.csv(file = paste0(out.path.batch, intervention, '_summary.csv'))
```

```{r}
calc_age_group <- function(batch.dat) {
  batch.dat <- batch.dat %>%
    mutate(age.group = cut(age, 
                            breaks = c(15, 30, 45, 60, 75, 120),
                            labels = c('16-30', '30-45', '45-60', '60-75', '75+')))
  return(batch.dat)
}

calc_income_quintile <- function(batch.dat) {
  batch.dat <- batch.dat %>%
    mutate(income.quint = cut(batch.dat$hh_income, breaks=c(quantile(batch.dat$hh_income, probs = seq(0, 1, by = 0.20))), 
                          labels=c(1,2,3,4,5), include.lowest=TRUE))
}

base.dat <- calc_age_group(base.dat)
int.dat <- calc_age_group(int.dat)

base.dat <- calc_income_quintile(base.dat)
int.dat <- calc_income_quintile(int.dat)
```

```{r}
# Function to calculate equivalent income using SIPHER calculation
# For this I asked chatGPT to port the Python function into R, so it's maybe
# not the best way to do this in R (I needed speed...)
calculate_equivalent_income <- function(data) {
  message('Calculating equivalent income...')
  
  # Setting up dictionaries for each variable to hold its factor weights
  phys_health_dict <- c(`5` = 0, 
                        `4` = -0.116/1.282, 
                        `3` = -0.135/1.282, 
                        `2` = -0.479/1.282, 
                        `1` = -0.837/1.282)
  men_health_dict <- c(`5` = 0, 
                       `4` = -0.14/1.282, 
                       `3` = -0.215/1.282, 
                       `2` = -0.656/1.282, 
                       `1` = -0.877/1.282)
  loneliness_dict <- c(`1` = 0, 
                       `2` = -0.186/1.282, 
                       `3` = -0.591/1.282)
  employment_dict <- c('FT Employed' = 0, 
                       'PT Employed' = 0.033/1.282, 
                       'Job Seeking' = -0.283/1.282, 
                       'FT Education' = -0.184/1.282, 
                       'Family Care' = -0.755/1.282, 
                       'Not Working' = -0.221/1.282)
  housing_dict <- c(`3` = 0, 
                    `2` = -0.235/1.282, 
                    `1` = -0.696/1.282)
  nh_safety_dict <- c(`3` = 0, 
                      `2` = -0.291/1.282,
                      `1` = -0.599/1.282)
  
  # Function to safely get value from dictionary
  get_dict_value <- function(x, dict) {
    if(is.na(x) || !as.character(x) %in% names(dict)) {
      return(NA)
    }
    return(dict[as.character(x)])
  }
  
  # print(typeof(data$S7_physical_health))
  # print(typeof(data$S7_mental_health))
  # print(typeof(data$loneliness))
  # print(typeof(data$S7_labour_state))
  # print(typeof(data$S7_housing_quality))
  # print(typeof(data$S7_neighbourhood_safety))
  
  # Creating the exponent term for modifying income to equivalent income
  data$EI_exp_term <- as.numeric(0)
  data$EI_exp_term <- data$EI_exp_term + sapply(data$S7_physical_health, function(x) get_dict_value(x, phys_health_dict))
  data$EI_exp_term <- data$EI_exp_term + sapply(data$S7_mental_health, function(x) get_dict_value(x, men_health_dict))
  data$EI_exp_term <- data$EI_exp_term + sapply(data$loneliness, function(x) get_dict_value(x, loneliness_dict))
  data$EI_exp_term <- data$EI_exp_term + sapply(data$S7_labour_state, function(x) get_dict_value(x, employment_dict))
  data$EI_exp_term <- data$EI_exp_term + sapply(data$S7_housing_quality, function(x) get_dict_value(x, housing_dict))
  data$EI_exp_term <- data$EI_exp_term + sapply(data$S7_neighbourhood_safety, function(x) get_dict_value(x, nh_safety_dict))
  
  # Calculate equivalent income
  data$hh_income_abs <- abs(data$hh_income)
  data$equivalent_income <- data$hh_income_abs * exp(data$EI_exp_term)
  
  print('Remaining Null values for Equivalent Income:')
  print(sum(is.na(data$equivalent_income)))
  
  # Adjusting the sign of the equivalent income based on the original income sign
  data$equivalent_income[(data$hh_income < 0) & !is.na(data$hh_income)] <- data$equivalent_income[(data$hh_income < 0) & !is.na(data$hh_income)] * -1
  
  
  # Handling missing values
  var_list_num <- c('S7_physical_health', 'S7_mental_health', 'loneliness')
  var_list_str <- c('S7_labour_state', 'S7_housing_quality', 'S7_neighbourhood_safety')
  data$equivalent_income[rowSums(data[var_list_num] < 0, na.rm = TRUE) > 0] <- -9
  data$equivalent_income[apply(data[var_list_str], 1, function(x) any(x %in% c('-1', '-2', '-7', '-8', '-9', '-10')))] <- '-9'
  
  # Dropping the EI_exp_term column
  data$EI_exp_term <- NULL
  data$hh_income_abs <- NULL
  
  return(data)
}

base.dat <- calculate_equivalent_income(base.dat)
int.dat <- calculate_equivalent_income(int.dat)
```

```{r}
# so need a function to generate a dataframe with all those additional metrics for the clustering

calculate_clustering_metrics <- function(base.dat, base.name, int.dat, int.name, target.year) {
  
  # first add scenario column to each
  base.dat <- base.dat %>%
    mutate(scenario = base.name)#,
           #boost_amount = 0,
           #income_boosted = 0)
  int.dat <- int.dat %>%
    mutate(scenario = int.name)
  
  miss.cols <- setdiff(names(int.dat), names(base.dat))
  print('Missing Columns!')
  print(miss.cols)
  
  # now bind together before subsetting
  combined <- rbind(base.dat, int.dat)
  
  # drop the original datafiles now for better memory handling with batch
  rm(base.dat, int.dat)
  
  combined <- combined %>%
    select(pidp, time, scenario, age, age.group, sex, ethnicity, region, education_state, hh_income, equivalent_income, S7_housing_quality, S7_neighbourhood_safety, S7_physical_health, S7_mental_health, S7_labour_state, loneliness, job_sec, nkids_ind) #hidp hourly_wage
  
  
  # combined$S7_housing_quality <- as.numeric(factor(combined$S7_housing_quality,
  #                                         levels = c('No to all',
  #                                                    'Yes to some',
  #                                                    'Yes to all'),
  #                                         labels = c(1, 2, 3)))
  # 
  # combined$S7_neighbourhood_safety <- as.numeric(factor(combined$S7_neighbourhood_safety,
  #                                              levels = c('Often',
  #                                                         'Some of the time',
  #                                                         'Hardly ever'),
  #                                              labels = c(1, 2, 3)))
  # 
  # combined$loneliness <- as.numeric(factor(combined$loneliness,
  #                                 levels = c(1, 2, 3),
  #                                 labels = c(3, 2, 1)))

  
  # Now calculate metrics. We need:
  # - change in Equivalent Income
  # - change in components
  #
  # This is all change from start.year (usually 2021) to target.year (start with 2031)
  combined <- combined %>%
    filter(time %in% c(target.year)) %>%
    pivot_wider(
      names_from = 'scenario',
      values_from = c('age', 'age.group', 'sex', 'ethnicity', 'region', 'education_state', 'hh_income', 'equivalent_income', 'S7_housing_quality', 'S7_neighbourhood_safety', 'S7_physical_health', 'S7_mental_health', 'S7_labour_state', 'loneliness', 'job_sec') # 'hourly_wage'
    )
  
  #return(combined)
  
  combined <- combined[complete.cases(combined), ]
  #return(combined)
  
  ############# Now calculate the difference between intervention and baseline in target.year ###########
  # List of variables to ignore (no difference calculation)
  ignore_vars <- c('pidp', 'time', 'nkids_ind') #'hidp'
  rename_vars <- c("age", "sex", "ethnicity", "region", "age.group", "S7_labour_state", "education_state")
  
  #return(combined)
  
  for (var in rename_vars) {
    combined <- combined %>%
      select(-contains(paste0(var, '_', intervention))) %>%
      rename(!!var := .data[[paste0(var, '_', base.name)]])
  }
  
  #return(combined)
  
  # Get the names of all variables in the 'combined' dataframe
  all_vars <- names(combined)
  
  # Find the variables that are in 'all_vars' but not in 'ignore_vars' or 'rename_vars'
  remaining_vars <- setdiff(all_vars, c(ignore_vars, rename_vars))
  # drop the scenarios suffixes
  remaining_vars <- lapply(remaining_vars, function(x) modified_string <- sub("_[^_]*$", "", x))
  remaining_vars <- unique(remaining_vars)
  
  # print('remaining_vars:')
  # print(remaining_vars)
  # 
  # print('colnames(combined)')
  # print(colnames(combined))
  # 
  # print('Set numeric types where necessary')
  
  # create EI var names with intervention suffix
  ei_base <- paste0('equivalent_income_', base.name)
  ei_var <- paste0('equivalent_income_', intervention)
  
  combined <- combined %>%
    mutate(!!ei_base := as.numeric(.data[[ei_base]]),
           !!ei_var := as.numeric(.data[[ei_var]]))

  
  print('Type of equivalent_income:')
  print(typeof(combined[[paste0('equivalent_income_', base.name)]]))
  print(typeof(combined[[paste0('equivalent_income_', intervention)]]))
  
  print('About to start final calculation')

  for (var in remaining_vars) {
    base.var <- paste0(var, '_', base.name)
    int.var <- paste0(var, '_', int.name)
    print(base.var)
    print(int.var)
    
    combined <- combined %>%
      mutate(!!var := !!sym(int.var) - !!sym(base.var)) %>%
      select(-base.var, -int.var)
  }
  
  # # Final step is to pivot long to get the run_id column back
  # combined <- combined %>%
  #   pivot_longer(age_baseline_1)
  
  return(combined)
}

# First calculate clustering metrics
combined <- calculate_clustering_metrics(base.dat, base.name = baseline, int.dat, int.name = intervention, target.year = 2031)
# Now remove original data for better memory handling
#rm(base.dat, int.dat)
```


# Testing Number of Clusters

```{r}
# so need a function to generate a dataframe with all those additional metrics for the clustering
#base.data <- base.dat
base.name <- baseline
int.name <- intervention

# # first add scenario column to each
# base <- base.dat %>%
#   mutate(scenarios = base.name)
# int <- int.dat %>%
#   mutate(scenarios = int.name)
# 
# # now bind together before subsetting
# combined2 <- rbind(base, int)
# combined2 <- combined2 %>%
#   select(pidp, time, age, sex, ethnicity, region, education_state, hh_income, equivalent_income, S7_housing_quality, S7_neighbourhood_safety, S7_physical_health, S7_mental_health, S7_labour_state, loneliness, job_sec, nkids_ind, hourly_wage)



# Identify categorical columns
categorical_cols <- c('sex', 'ethnicity', 'region', 'education_state', 'S7_housing_quality', 'S7_neighbourhood_safety', 'S7_physical_health', 'S7_mental_health', 'S7_labour_state', 'loneliness', 'job_sec')

# Convert categorical variables to factors
combined[, categorical_cols] <- lapply(combined[, categorical_cols], as.factor)

# Choose a range of values for 'k' (number of clusters)
k_values <- 2:6 # You can adjust the range

# Initialize vectors to store evaluation metrics
wss <- vector('numeric', length(k_values))  # Within-cluster sum of squares
#silhouette_scores <- vector('numeric', length(k_values))


# Iterate through different values of 'k'
for (i in 1:length(k_values)) {
  # Fit the k-prototypes model
  kp_model <- kproto(combined, k = k_values[i], num_rounds = 20, verbose = FALSE, cat.vars = which(names(combined2) %in% categorical_columns))
  # Compute within-cluster sum of squares
  wss[i] <- kp_model$tot.withinss
  # Compute silhouette score
  # Silhouette score measures the quality of clustering (higher is better)
  #silhouette_scores[i] <- silhouette(kp_model$cluster, dist(combined))$avg.width
}

# Plot the elbow curve
#par(mfrow = c(1, 2))
plot(k_values, wss, type = "b", pch = 19, xlab = "Number of Clusters (k)", ylab = "Within-Cluster Sum of Squares (WSS)", main = "Elbow Method")
#plot(k_values, silhouette_scores, type = "b", pch = 19, xlab = "Number of Clusters (k)", ylab = "Silhouette Score", main = "Silhouette Score Method")

# Use the elbow or silhouette method to select the optimal number of clusters
# Elbow method: Look for an 'elbow point' where the WSS starts to level off
# Silhouette method: Look for the highest silhouette score
```



```{r}

```

